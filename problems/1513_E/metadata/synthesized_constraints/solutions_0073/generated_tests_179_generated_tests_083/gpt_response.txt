=== Invariants Response ===
### Phase 1: Identify Expensive or Inefficient Code Segments

**1. Compare Line-Level Hit Counts:**
- The `binPow` function (lines 14-23) is called multiple times during the slow input execution, particularly lines 17-21, indicating repeated exponentiation operations.
- The loop for computing factorials (line 41) is executed 100,001 times in the slow run, which is inherently expensive.

**2. Pinpoint Lines or Functions with More Hits:**
- `binPow` function: This function is part of the modular inverse calculation, which is computationally intensive, especially when called multiple times.
- Factorial computation: Line 41 is executed a large number of times, indicating that precomputing factorials for all values up to 100,000 is resource-intensive.

**3. Interaction with Data Structures:**
- The factorial array (`fact`) precomputes factorials up to 100,000, which is necessary for combinatorial calculations in the solution.
- The hit count suggests that the main computational load is in managing permutations and factorial-based operations, especially when determining the number of balanced permutations.

### Phase 2: Derive Performance-Characterizing Invariants

**1. Natural Language Performance Invariants:**

**Invariant 1: High Exponentiation Load**
- **Description:** "If the function `binPow` is called repeatedly for large values, the computation may become slow due to the intensive modular exponentiation operations."
- **Reasoning:** The function `binPow` is a key contributor to performance degradation as it is hit numerous times for the slow input. This function is used to compute modular inverses, which are necessary when handling permutations and factorials.

**Invariant 2: Extensive Factorial Calculation**
- **Description:** "For arrays with a large number of distinct elements far from the mean, the program may slow down due to extensive precomputation of factorial values and associated combinatorial calculations."
- **Reasoning:** The observed lines indicate that the factorial calculation loop is a major computational burden, especially for inputs requiring permutation operations that involve large differences from the mean.

**Invariant 3: Balance Characteristic Complexity**
- **Description:** "When the array's elements have significant imbalance regarding their mean, leading to many sources and sinks, the program's complexity increases due to the combinatorial nature of balanced permutations."
- **Reasoning:** The combinatorial logic handling sources and sinks (elements above and below the mean) becomes complex, requiring detailed management of factorial and permutation calculations.

**2. Broader Conditions for Slow Execution:**
- These invariants capture the essence of where computations can become costly, focusing on heavy arithmetic operations (like exponentiation) and extensive factorial operations, all underpinned by the logic of balancing permutations.

By understanding these conditions, scenarios where similar patterns arise can be identified, allowing for preemptive performance tuning or optimization strategies to be employed in future cases.

=== Checker Response ===
### Phase 3: Implementing the Invariants in C++

Let's create C++ functions to check each of the performance-characterizing invariants derived in the previous phase.

**Invariant 1: High Exponentiation Load**

```cpp
void check_exponentiation_invariant(bool condition) {
    if (condition) {
        cerr << "Warning: Performance bottleneck condition triggered due to high exponentiation load!" << endl;
        abort();
    }
}
```

**Invariant 2: Extensive Factorial Calculation**

```cpp
void check_factorial_calculation_invariant(bool condition) {
    if (condition) {
        cerr << "Warning: Performance bottleneck condition triggered due to excessive factorial calculation!" << endl;
        abort();
    }
}
```

**Invariant 3: Balance Characteristic Complexity**

```cpp
void check_balance_complexity_invariant(bool condition) {
    if (condition) {
        cerr << "Warning: Performance bottleneck condition triggered due to complex balance characteristics!" << endl;
        abort();
    }
}
```

### Phase 4: Integrating the Checkers into the C++ Program

Now, let's integrate these checks into the original C++ code:

```cpp
#include <iostream>
#include <vector>
#include <numeric>
#include <map>

using namespace std;

#define int long long

typedef long long ll;

const ll MOD = 1e9 + 7;

ll binPow(ll a, ll n)
{
    ll res = 1;
    while (n)
    {
        if (n & 1) res = (res * a) % MOD;
        a = (a * a) % MOD;
        n /= 2;
    }
    return res;
}

void check_exponentiation_invariant(bool condition) {
    if (condition) {
        cerr << "Warning: Performance bottleneck condition triggered due to high exponentiation load!" << endl;
        abort();
    }
}

void check_factorial_calculation_invariant(bool condition) {
    if (condition) {
        cerr << "Warning: Performance bottleneck condition triggered due to excessive factorial calculation!" << endl;
        abort();
    }
}

void check_balance_complexity_invariant(bool condition) {
    if (condition) {
        cerr << "Warning: Performance bottleneck condition triggered due to complex balance characteristics!" << endl;
        abort();
    }
}

signed main()
{
    int n;
    cin >> n;
    vector<int> a(n);
    for (int &i : a) cin >> i;
    ll sum = accumulate(a.begin(), a.end(), 0ll);
    if (sum % n != 0)
    {
        cout << 0;
        return 0;
    }
    sum /= n;
    
    // Check for potential factorial calculation bottleneck
    check_factorial_calculation_invariant(n > 50000); // Adjust threshold accordingly

    vector<ll> fact(1e5 + 1);
    fact[0] = 1;
    for (ll i = 1; i <= 1e5; ++i) fact[i] = (fact[i - 1] * i) % MOD;
    int sources = 0, sinks = 0;
    for (int i : a)
    {
        if (i < sum) ++sinks;
        if (i > sum) ++sources;
    }
    
    // Check for potential balance complexity bottleneck
    check_balance_complexity_invariant(sources > n / 2 && sinks > n / 2); // Adjust conditions to detect complex balances

    ll res = 1;
    if (sinks <= 1 || sources <= 1)
    {
        res = fact[n];
        map<int, int> help;
        for (int i : a) ++help[i];
        for (auto i : help) res = (res * binPow(fact[i.second], MOD - 2)) % MOD;
    }
    else
    {
        res = (((((2 * fact[n]) % MOD) * binPow(fact[sources + sinks], MOD - 2)) % MOD) * binPow(fact[n - sources - sinks], MOD - 2)) % MOD;
        res = (res * fact[sources]) % MOD;
        res = (res * fact[sinks]) % MOD;
        map<int, int> help;
        for (int i : a) if (i != sum) ++help[i];
        for (auto i : help) res = (res * binPow(fact[i.second], MOD - 2)) % MOD;
    }
    
    // Check for potential exponentiation bottleneck
    check_exponentiation_invariant(res > MOD); // A simple condition to illustrate checking during result calculation

    cout << res;
    return 0;
}
```

**Comments on Instrumentation:**
- The checks are placed strategically before major computational burdens or complex logic begins.
- Thresholds are chosen based on logical limits derived from the problem constraints and common performance understanding.
- These checks help identify potential performance bottlenecks during execution without adding substantial overhead.
